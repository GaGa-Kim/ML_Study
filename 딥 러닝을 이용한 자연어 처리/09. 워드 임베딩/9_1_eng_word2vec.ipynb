{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 영어 Word2Vec 실습"
      ],
      "metadata": {
        "id": "gCyaWF-_CCKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 파이썬의 genism 패키지의 Word2Vec 사용하기"
      ],
      "metadata": {
        "id": "ONHzyYWECTZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) 파이썬의 genism 패키지에는 Word2Vec을 지원하고 있어 손쉽게 단어를 임베딩 벡터로 변환할 수 있음**"
      ],
      "metadata": {
        "id": "iN3DTsEyDXlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "gensim.__version__"
      ],
      "metadata": {
        "id": "9sXoCmanCu92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f6dc3b36-d810-4d6f-dfc8-4b9392daf0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.6.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "id": "k1lzUgLNCvQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8b227c-6624-45c1-876d-8ea66a9c317b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.1)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[K     |████████████████████████████████| 465 kB 49.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "nekEEjg6C6mP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d9446e-da93-47ca-ce3c-0e73880d3fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "from lxml import etree\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "id": "ACABrlfVC_ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련 데이터 이해하기"
      ],
      "metadata": {
        "id": "-GN-JBGWCVIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) 훈련 데이터를 다운로드**"
      ],
      "metadata": {
        "id": "YNmlSWlxDZQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 다운로드\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCc2n8IUi06u",
        "outputId": "9fcf85a8-718a-495a-92ae-fdad03119246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ted_en-20160408.xml', <http.client.HTTPMessage at 0x7effe0d4a810>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련 데이터 전처리하기"
      ],
      "metadata": {
        "id": "lQyJ4SQgCWWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) xml 문법으로 작성된 파일에 대해 xml 문법들과 배경음을 나타내는 단어들을 제거하고 자연어 데이터만 가져오도록 전처리**<br>\n",
        "**2) 또한 입력 코퍼스에 대해서 단어 토큰화를 수행**"
      ],
      "metadata": {
        "id": "mid6jCrGDbAu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZI00TbvLKCI"
      },
      "source": [
        "targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
        "target_text = etree.parse(targetXML)\n",
        "\n",
        "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n",
        "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
        "\n",
        "# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n",
        "# 해당 코드는 괄호로 구성된 내용을 제거.\n",
        "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
        "\n",
        "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n",
        "sent_text = sent_tokenize(content_text)\n",
        "\n",
        "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n",
        "normalized_text = []\n",
        "for string in sent_text:\n",
        "     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
        "     normalized_text.append(tokens)\n",
        "\n",
        "# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행.\n",
        "result = [word_tokenize(sentence) for sentence in normalized_text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) 총 샘플의 개수는 27만 3천개 이며 상위 3개 문장을 출력하면 토큰화가 수행되었음을 볼 수 있음**"
      ],
      "metadata": {
        "id": "n7dmTJ8dDgem"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUqiRKAmLLg9",
        "outputId": "8380b707-75cb-4959-df00-f2f003c412b9"
      },
      "source": [
        "print('총 샘플의 개수 : {}'.format(len(result)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 개수 : 273424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA1Kr9UkLMfL",
        "outputId": "6b3b8ba0-6cb8-40b3-b803-5999fbde088a"
      },
      "source": [
        "# 샘플 3개만 출력\n",
        "for line in result[:3]:\n",
        "    print(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
            "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
            "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word2Vec 훈련시키기"
      ],
      "metadata": {
        "id": "QyKZEmYSCXOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "jMM1jtPTDOIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Word2Vec에 대해서 학습을 진행**"
      ],
      "metadata": {
        "id": "mt94MUyLDik6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.\n",
        "# window = 컨텍스트 윈도우 크기\n",
        "# min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\n",
        "# workers = 학습을 위한 프로세스 수\n",
        "# sg = 0은 CBOW, 1은 Skip-gram.\n",
        "model = Word2Vec(sentences=result, size=100, window=5, min_count=5, workers=4, sg=0)"
      ],
      "metadata": {
        "id": "D453aQJ9DPK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Word2Vec은 입력한 단어에 대해서 가장 유사한 단어들을 출력하는 model.wv.most_similer을 지원하므로**<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;     **Word2Vec을 통해 단어의 유사도를 계산하여 man과 가장 유사한 단어들을 출력해보도록 함**"
      ],
      "metadata": {
        "id": "qSQQLWntDlDS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVmN8NWjLkdg",
        "outputId": "1c37ffb2-ba8f-4a95-8849-18bbf4402967"
      },
      "source": [
        "model_result = model.wv.most_similar(\"man\")\n",
        "print(model_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('woman', 0.8424811363220215), ('guy', 0.8290940523147583), ('boy', 0.7704038619995117), ('lady', 0.7589364051818848), ('girl', 0.7309212684631348), ('soldier', 0.7116029858589172), ('gentleman', 0.7100744247436523), ('kid', 0.6928150057792664), ('poet', 0.6735016107559204), ('friend', 0.6649017333984375)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word2Vec 모델 저장하고 로드하기"
      ],
      "metadata": {
        "id": "qBPTLy4YCYC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) 학습한 모델을 언제든 다시 사용할 수 있도록 컴퓨터 파일에 저장하고 다시 로드해보도록 함**"
      ],
      "metadata": {
        "id": "BQNr2UG7D3nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.save_word2vec_format('eng_w2v') # 모델 저장\n",
        "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드"
      ],
      "metadata": {
        "id": "NhXqqN0ODTwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) 로드한 모델에 대해서 다시 man과 유사한 단어를 출력해보도록 함**"
      ],
      "metadata": {
        "id": "jFNhGE_4D5Y2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFXguci-L2Gz",
        "outputId": "2d0372f2-f751-4d89-9cb3-39dadf6009ab"
      },
      "source": [
        "model_result = loaded_model.most_similar(\"man\")\n",
        "print(model_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('woman', 0.8424811363220215), ('guy', 0.8290940523147583), ('boy', 0.7704038619995117), ('lady', 0.7589364051818848), ('girl', 0.7309212684631348), ('soldier', 0.7116029858589172), ('gentleman', 0.7100744247436523), ('kid', 0.6928150057792664), ('poet', 0.6735016107559204), ('friend', 0.6649017333984375)]\n"
          ]
        }
      ]
    }
  ]
}