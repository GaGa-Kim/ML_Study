{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-8. one_hot_encoding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 원-핫 인코딩이란?"
      ],
      "metadata": {
        "id": "I3-mVJncgqCx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 원-핫 인코딩 방법"
      ],
      "metadata": {
        "id": "VICZ0z_YgqdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Okt 형태소 분석기를 통해서 문장에 대해서 토큰화를 수행**"
      ],
      "metadata": {
        "id": "RYLrKYuwgsG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U2N0x6jhNRP",
        "outputId": "86a686d0-d458-426c-b421-4ea19869be94"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 43.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt  \n",
        "\n",
        "okt = Okt()  \n",
        "tokens = okt.morphs(\"나는 자연어 처리를 배운다\")  \n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1YpGGkPhN1-",
        "outputId": "735bb0e8-fcce-41b7-9b41-83fb37b815ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['나', '는', '자연어', '처리', '를', '배운다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) 각 토큰에 대해서 고유한 정수를 부여**"
      ],
      "metadata": {
        "id": "g4EdRRX8gx23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**여기서는 빈도수 순으로 단어를 정렬하여 정수를 부여**"
      ],
      "metadata": {
        "id": "OdRz7QKUgz22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {word : index for index, word in enumerate(tokens)}\n",
        "print('단어 집합 :',word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWysCgIPhPm5",
        "outputId": "48dd39f0-fc17-4778-fb74-0356f60ed6e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합 : {'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) 토큰을 입력하면 해당 토큰에 대한 원-핫 벡터를 만들어내는 함수 생성**"
      ],
      "metadata": {
        "id": "9L8Mlx20g1mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(word, word_to_index):\n",
        "  one_hot_vector = [0]*(len(word_to_index))\n",
        "  index = word_to_index[word]\n",
        "  one_hot_vector[index] = 1\n",
        "  return one_hot_vector"
      ],
      "metadata": {
        "id": "uMNv1vuahTe1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) 생성한 함수를 사용해 단어의 원-핫 벡터 얻기**"
      ],
      "metadata": {
        "id": "IO9C7zilg39n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoding(\"자연어\", word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCynUXkvhUW_",
        "outputId": "c507fee3-b7e7-42a3-8e27-14a3331d833f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 1, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 케라스를 이용한 원-핫 인코딩"
      ],
      "metadata": {
        "id": "KaJoIPyRg5r3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 케라스를 이용한 원-핫 인코딩 방법"
      ],
      "metadata": {
        "id": "YBKPwovrhA-H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) 케라스의 Tokenizer를 이용해 정수 인코딩**"
      ],
      "metadata": {
        "id": "SUGUsipVhBCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "text = \"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\"\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "print('단어 집합 :',tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19g6Z2BchVp_",
        "outputId": "ce6f1585-60f0-48a3-9422-a3c2b179c97c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합 : {'갈래': 1, '점심': 2, '햄버거': 3, '나랑': 4, '먹으러': 5, '메뉴는': 6, '최고야': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) 케라스의 texts_to_sequences()를 통해서 단어들로 구성된 텍스트를 정수 시퀀스로 변환**"
      ],
      "metadata": {
        "id": "yaips_3OhFP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_text = \"점심 먹으러 갈래 메뉴는 햄버거 최고야\"\n",
        "encoded = tokenizer.texts_to_sequences([sub_text])[0]\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6JrJgzShW9H",
        "outputId": "3b4fb09a-c489-4f70-fad4-cc2947bde894"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 5, 1, 6, 3, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) 케라스의 to_categorical()을 통해서 정수 인코딩된 결과로부터 원-핫 인코딩을 수행**"
      ],
      "metadata": {
        "id": "1ITZ18G9hHVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot = to_categorical(encoded)\n",
        "print(one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFZ8hUxNheuX",
        "outputId": "8c758183-3faa-4b80-c876-e11322f0858b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    }
  ]
}