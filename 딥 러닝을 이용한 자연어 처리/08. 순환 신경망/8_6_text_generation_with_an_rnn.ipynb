{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RNN을 이용한 텍스트 생성"
      ],
      "metadata": {
        "id": "_zAporLjT9yh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 다 대 일 구조의 RNN을 사용하여 문맥을 반영하여 텍스트를 생성하는 모델 만들기"
      ],
      "metadata": {
        "id": "sq5pCgFhT-K6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN을 이용하여 텍스트 생성하기"
      ],
      "metadata": {
        "id": "RCi374BBT-1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) 데이터에 대한 이해와 전처리**"
      ],
      "metadata": {
        "id": "9xTouWI7UAmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "Ny3xOnECUIQq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
        "그의 말이 법이다\\n\n",
        "가는 말이 고와야 오는 말이 곱다\\n\"\"\""
      ],
      "metadata": {
        "id": "BjrrL2h2UMRa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3개의 한국어 문장을 저장하고 단어 집합을 생성한 후 패딩을 위해 0을 고려하여 +1을 해준 후<br>단어 집합의 크기와 각 단어에 부여된 정수 인덱스를 확인"
      ],
      "metadata": {
        "id": "GBAskpBuV0kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : %d' % vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWQ7jWVuUPxS",
        "outputId": "14d097b1-2d10-402f-c058-3d38da986c34"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8_z9gX5UQUS",
        "outputId": "6c821736-ee44-4520-da4d-e72e6740da90"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11개의 샘플을 만들어 훈련 데이터로 사용하기 위해 줄바꿈 문자를 기준으로 문장을 토큰화한 후 전체 샘플을 출력"
      ],
      "metadata": {
        "id": "zZgX3gtZV_h0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![캡처.PNG](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "IGmK55SHWEmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = list()\n",
        "for line in text.split('\\n'): # Wn을 기준으로 문장 토큰화\n",
        "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "print('학습에 사용할 샘플의 개수: %d' % len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTxLF3LGURDQ",
        "outputId": "9a6b9858-c44f-4287-c77a-51399cef9f5b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습에 사용할 샘플의 개수: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF9FkzVlUR6A",
        "outputId": "959c9b92-2e92-48a4-a676-1064befdc212"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "레이블로 사용될 단어를 분리하지 않았으므로 전체 훈련 데이터에서 가장 긴 샘플의 길이를 이용해 전체 샘플의 길이를 패딩<br>그 후  전체 훈련 데이터에 대해서 맨 우측에 있는 단어에 대해서만 레이블로 분리하도록 함"
      ],
      "metadata": {
        "id": "so4xdS4UWLHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in sequences) # 모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\n",
        "print('샘플의 최대 길이 : {}'.format(max_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onyYvODsUSsf",
        "outputId": "190fdde3-f5a6-4633-a7dd-379bc84f51d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"
      ],
      "metadata": {
        "id": "SdVmBdn3UUcY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm3w6XU5UVKz",
        "outputId": "e159148e-49af-4d85-bdeb-372540d69af9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  2  3]\n",
            " [ 0  0  0  2  3  1]\n",
            " [ 0  0  2  3  1  4]\n",
            " [ 0  2  3  1  4  5]\n",
            " [ 0  0  0  0  6  1]\n",
            " [ 0  0  0  6  1  7]\n",
            " [ 0  0  0  0  8  1]\n",
            " [ 0  0  0  8  1  9]\n",
            " [ 0  0  8  1  9 10]\n",
            " [ 0  8  1  9 10  1]\n",
            " [ 8  1  9 10  1 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1]"
      ],
      "metadata": {
        "id": "G6nTQi2yUWFL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5JzUDkWUWf6",
        "outputId": "f4f5c031-4609-4712-c874-0a81349637b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  2]\n",
            " [ 0  0  0  2  3]\n",
            " [ 0  0  2  3  1]\n",
            " [ 0  2  3  1  4]\n",
            " [ 0  0  0  0  6]\n",
            " [ 0  0  0  6  1]\n",
            " [ 0  0  0  0  8]\n",
            " [ 0  0  0  8  1]\n",
            " [ 0  0  8  1  9]\n",
            " [ 0  8  1  9 10]\n",
            " [ 8  1  9 10  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y) # 모든 샘플에 대한 레이블 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qdhGODcUXV4",
        "outputId": "7b173b51-362e-4739-e0bc-e922801343a1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막으로 RNN 모델에 훈련 데이터를 훈련 시키기 전에 레이블에 대해서 원-핫 인코딩을 수행"
      ],
      "metadata": {
        "id": "IgmHQi6KWQU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "-KUjMC8qUYcq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAfcHG2nUZgB",
        "outputId": "9f18f2bd-801f-4081-d004-a8647ae4f753"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) 모델 설계하기**"
      ],
      "metadata": {
        "id": "XMuW4DkWUBso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN"
      ],
      "metadata": {
        "id": "p83rBNUAUbRh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼파라미터인 임베딩 벡터의 차원은 10, 은닉 상태의 크기는 32로 하고 다 대 일 구조의 RNN을 사용<br>\n",
        "그리고 전결합층을 출력층으로 하여 단어 집합 크기만큼의 뉴런을 배치하여 모델을 설계하도록 함<br>\n",
        "해당 모델은 마지막 시점에서 모든 가능한 단어 중 하나의 단어를 예측하는 다중 클래스 분류 문제를 수행하는 것이므로<br>\n",
        "출력층에서 활성화 함수로는 소프트맥스 함수를 사용하고, 손실 함수로는 크로스 엔트로피 함수를 사용하여 200 에포크 수행"
      ],
      "metadata": {
        "id": "ARbs64EGWSC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 10\n",
        "hidden_units = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(SimpleRNN(hidden_units))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hysUoIw8Ub_I",
        "outputId": "db962a47-32ca-4ad6-bc69-de3e35645922"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 - 1s - loss: 2.5132 - accuracy: 0.0909 - 1s/epoch - 1s/step\n",
            "Epoch 2/200\n",
            "1/1 - 0s - loss: 2.5019 - accuracy: 0.0909 - 8ms/epoch - 8ms/step\n",
            "Epoch 3/200\n",
            "1/1 - 0s - loss: 2.4911 - accuracy: 0.0909 - 8ms/epoch - 8ms/step\n",
            "Epoch 4/200\n",
            "1/1 - 0s - loss: 2.4807 - accuracy: 0.0909 - 9ms/epoch - 9ms/step\n",
            "Epoch 5/200\n",
            "1/1 - 0s - loss: 2.4706 - accuracy: 0.1818 - 9ms/epoch - 9ms/step\n",
            "Epoch 6/200\n",
            "1/1 - 0s - loss: 2.4607 - accuracy: 0.2727 - 7ms/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "1/1 - 0s - loss: 2.4509 - accuracy: 0.2727 - 8ms/epoch - 8ms/step\n",
            "Epoch 8/200\n",
            "1/1 - 0s - loss: 2.4410 - accuracy: 0.2727 - 8ms/epoch - 8ms/step\n",
            "Epoch 9/200\n",
            "1/1 - 0s - loss: 2.4309 - accuracy: 0.2727 - 9ms/epoch - 9ms/step\n",
            "Epoch 10/200\n",
            "1/1 - 0s - loss: 2.4207 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 11/200\n",
            "1/1 - 0s - loss: 2.4101 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 12/200\n",
            "1/1 - 0s - loss: 2.3991 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 13/200\n",
            "1/1 - 0s - loss: 2.3877 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "1/1 - 0s - loss: 2.3756 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 15/200\n",
            "1/1 - 0s - loss: 2.3628 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 16/200\n",
            "1/1 - 0s - loss: 2.3493 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 17/200\n",
            "1/1 - 0s - loss: 2.3350 - accuracy: 0.3636 - 12ms/epoch - 12ms/step\n",
            "Epoch 18/200\n",
            "1/1 - 0s - loss: 2.3198 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "1/1 - 0s - loss: 2.3037 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 20/200\n",
            "1/1 - 0s - loss: 2.2866 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 21/200\n",
            "1/1 - 0s - loss: 2.2686 - accuracy: 0.3636 - 11ms/epoch - 11ms/step\n",
            "Epoch 22/200\n",
            "1/1 - 0s - loss: 2.2496 - accuracy: 0.3636 - 11ms/epoch - 11ms/step\n",
            "Epoch 23/200\n",
            "1/1 - 0s - loss: 2.2297 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 24/200\n",
            "1/1 - 0s - loss: 2.2090 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 25/200\n",
            "1/1 - 0s - loss: 2.1876 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 26/200\n",
            "1/1 - 0s - loss: 2.1656 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 27/200\n",
            "1/1 - 0s - loss: 2.1433 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "1/1 - 0s - loss: 2.1209 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "1/1 - 0s - loss: 2.0985 - accuracy: 0.3636 - 11ms/epoch - 11ms/step\n",
            "Epoch 30/200\n",
            "1/1 - 0s - loss: 2.0766 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 31/200\n",
            "1/1 - 0s - loss: 2.0552 - accuracy: 0.3636 - 12ms/epoch - 12ms/step\n",
            "Epoch 32/200\n",
            "1/1 - 0s - loss: 2.0346 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "1/1 - 0s - loss: 2.0149 - accuracy: 0.3636 - 13ms/epoch - 13ms/step\n",
            "Epoch 34/200\n",
            "1/1 - 0s - loss: 1.9961 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 35/200\n",
            "1/1 - 0s - loss: 1.9781 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "1/1 - 0s - loss: 1.9608 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "1/1 - 0s - loss: 1.9440 - accuracy: 0.3636 - 13ms/epoch - 13ms/step\n",
            "Epoch 38/200\n",
            "1/1 - 0s - loss: 1.9276 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
            "Epoch 39/200\n",
            "1/1 - 0s - loss: 1.9114 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 40/200\n",
            "1/1 - 0s - loss: 1.8953 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "1/1 - 0s - loss: 1.8791 - accuracy: 0.3636 - 13ms/epoch - 13ms/step\n",
            "Epoch 42/200\n",
            "1/1 - 0s - loss: 1.8628 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 43/200\n",
            "1/1 - 0s - loss: 1.8464 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 44/200\n",
            "1/1 - 0s - loss: 1.8300 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 45/200\n",
            "1/1 - 0s - loss: 1.8134 - accuracy: 0.3636 - 13ms/epoch - 13ms/step\n",
            "Epoch 46/200\n",
            "1/1 - 0s - loss: 1.7968 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
            "Epoch 47/200\n",
            "1/1 - 0s - loss: 1.7801 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 48/200\n",
            "1/1 - 0s - loss: 1.7633 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 49/200\n",
            "1/1 - 0s - loss: 1.7464 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 50/200\n",
            "1/1 - 0s - loss: 1.7294 - accuracy: 0.3636 - 11ms/epoch - 11ms/step\n",
            "Epoch 51/200\n",
            "1/1 - 0s - loss: 1.7123 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 52/200\n",
            "1/1 - 0s - loss: 1.6949 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 53/200\n",
            "1/1 - 0s - loss: 1.6772 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
            "Epoch 54/200\n",
            "1/1 - 0s - loss: 1.6592 - accuracy: 0.4545 - 9ms/epoch - 9ms/step\n",
            "Epoch 55/200\n",
            "1/1 - 0s - loss: 1.6408 - accuracy: 0.5455 - 8ms/epoch - 8ms/step\n",
            "Epoch 56/200\n",
            "1/1 - 0s - loss: 1.6219 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 57/200\n",
            "1/1 - 0s - loss: 1.6026 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 58/200\n",
            "1/1 - 0s - loss: 1.5828 - accuracy: 0.5455 - 10ms/epoch - 10ms/step\n",
            "Epoch 59/200\n",
            "1/1 - 0s - loss: 1.5626 - accuracy: 0.5455 - 12ms/epoch - 12ms/step\n",
            "Epoch 60/200\n",
            "1/1 - 0s - loss: 1.5420 - accuracy: 0.5455 - 10ms/epoch - 10ms/step\n",
            "Epoch 61/200\n",
            "1/1 - 0s - loss: 1.5209 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 62/200\n",
            "1/1 - 0s - loss: 1.4995 - accuracy: 0.5455 - 13ms/epoch - 13ms/step\n",
            "Epoch 63/200\n",
            "1/1 - 0s - loss: 1.4777 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 64/200\n",
            "1/1 - 0s - loss: 1.4557 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 65/200\n",
            "1/1 - 0s - loss: 1.4335 - accuracy: 0.5455 - 10ms/epoch - 10ms/step\n",
            "Epoch 66/200\n",
            "1/1 - 0s - loss: 1.4110 - accuracy: 0.5455 - 8ms/epoch - 8ms/step\n",
            "Epoch 67/200\n",
            "1/1 - 0s - loss: 1.3884 - accuracy: 0.5455 - 11ms/epoch - 11ms/step\n",
            "Epoch 68/200\n",
            "1/1 - 0s - loss: 1.3656 - accuracy: 0.6364 - 10ms/epoch - 10ms/step\n",
            "Epoch 69/200\n",
            "1/1 - 0s - loss: 1.3428 - accuracy: 0.6364 - 10ms/epoch - 10ms/step\n",
            "Epoch 70/200\n",
            "1/1 - 0s - loss: 1.3199 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 71/200\n",
            "1/1 - 0s - loss: 1.2970 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n",
            "Epoch 72/200\n",
            "1/1 - 0s - loss: 1.2742 - accuracy: 0.6364 - 16ms/epoch - 16ms/step\n",
            "Epoch 73/200\n",
            "1/1 - 0s - loss: 1.2515 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 74/200\n",
            "1/1 - 0s - loss: 1.2290 - accuracy: 0.6364 - 7ms/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "1/1 - 0s - loss: 1.2067 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 76/200\n",
            "1/1 - 0s - loss: 1.1846 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 77/200\n",
            "1/1 - 0s - loss: 1.1628 - accuracy: 0.6364 - 10ms/epoch - 10ms/step\n",
            "Epoch 78/200\n",
            "1/1 - 0s - loss: 1.1413 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 79/200\n",
            "1/1 - 0s - loss: 1.1201 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
            "Epoch 80/200\n",
            "1/1 - 0s - loss: 1.0994 - accuracy: 0.6364 - 13ms/epoch - 13ms/step\n",
            "Epoch 81/200\n",
            "1/1 - 0s - loss: 1.0790 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 82/200\n",
            "1/1 - 0s - loss: 1.0589 - accuracy: 0.6364 - 7ms/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "1/1 - 0s - loss: 1.0393 - accuracy: 0.6364 - 10ms/epoch - 10ms/step\n",
            "Epoch 84/200\n",
            "1/1 - 0s - loss: 1.0201 - accuracy: 0.6364 - 7ms/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "1/1 - 0s - loss: 1.0013 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 86/200\n",
            "1/1 - 0s - loss: 0.9829 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 87/200\n",
            "1/1 - 0s - loss: 0.9648 - accuracy: 0.7273 - 7ms/epoch - 7ms/step\n",
            "Epoch 88/200\n",
            "1/1 - 0s - loss: 0.9472 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n",
            "Epoch 89/200\n",
            "1/1 - 0s - loss: 0.9298 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 90/200\n",
            "1/1 - 0s - loss: 0.9128 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n",
            "Epoch 91/200\n",
            "1/1 - 0s - loss: 0.8961 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 92/200\n",
            "1/1 - 0s - loss: 0.8797 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 93/200\n",
            "1/1 - 0s - loss: 0.8636 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 94/200\n",
            "1/1 - 0s - loss: 0.8477 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 95/200\n",
            "1/1 - 0s - loss: 0.8320 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n",
            "Epoch 96/200\n",
            "1/1 - 0s - loss: 0.8166 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 97/200\n",
            "1/1 - 0s - loss: 0.8013 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n",
            "Epoch 98/200\n",
            "1/1 - 0s - loss: 0.7863 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 99/200\n",
            "1/1 - 0s - loss: 0.7714 - accuracy: 0.7273 - 15ms/epoch - 15ms/step\n",
            "Epoch 100/200\n",
            "1/1 - 0s - loss: 0.7568 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n",
            "Epoch 101/200\n",
            "1/1 - 0s - loss: 0.7423 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n",
            "Epoch 102/200\n",
            "1/1 - 0s - loss: 0.7281 - accuracy: 0.8182 - 9ms/epoch - 9ms/step\n",
            "Epoch 103/200\n",
            "1/1 - 0s - loss: 0.7140 - accuracy: 0.8182 - 13ms/epoch - 13ms/step\n",
            "Epoch 104/200\n",
            "1/1 - 0s - loss: 0.7002 - accuracy: 0.8182 - 12ms/epoch - 12ms/step\n",
            "Epoch 105/200\n",
            "1/1 - 0s - loss: 0.6866 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n",
            "Epoch 106/200\n",
            "1/1 - 0s - loss: 0.6732 - accuracy: 0.8182 - 9ms/epoch - 9ms/step\n",
            "Epoch 107/200\n",
            "1/1 - 0s - loss: 0.6600 - accuracy: 0.8182 - 10ms/epoch - 10ms/step\n",
            "Epoch 108/200\n",
            "1/1 - 0s - loss: 0.6470 - accuracy: 0.8182 - 8ms/epoch - 8ms/step\n",
            "Epoch 109/200\n",
            "1/1 - 0s - loss: 0.6342 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n",
            "Epoch 110/200\n",
            "1/1 - 0s - loss: 0.6217 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n",
            "Epoch 111/200\n",
            "1/1 - 0s - loss: 0.6093 - accuracy: 0.8182 - 8ms/epoch - 8ms/step\n",
            "Epoch 112/200\n",
            "1/1 - 0s - loss: 0.5972 - accuracy: 0.8182 - 13ms/epoch - 13ms/step\n",
            "Epoch 113/200\n",
            "1/1 - 0s - loss: 0.5854 - accuracy: 0.8182 - 9ms/epoch - 9ms/step\n",
            "Epoch 114/200\n",
            "1/1 - 0s - loss: 0.5737 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 115/200\n",
            "1/1 - 0s - loss: 0.5622 - accuracy: 0.9091 - 11ms/epoch - 11ms/step\n",
            "Epoch 116/200\n",
            "1/1 - 0s - loss: 0.5510 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 117/200\n",
            "1/1 - 0s - loss: 0.5399 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
            "Epoch 118/200\n",
            "1/1 - 0s - loss: 0.5291 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 119/200\n",
            "1/1 - 0s - loss: 0.5184 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 120/200\n",
            "1/1 - 0s - loss: 0.5080 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 121/200\n",
            "1/1 - 0s - loss: 0.4977 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
            "Epoch 122/200\n",
            "1/1 - 0s - loss: 0.4876 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 123/200\n",
            "1/1 - 0s - loss: 0.4777 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 124/200\n",
            "1/1 - 0s - loss: 0.4680 - accuracy: 0.9091 - 11ms/epoch - 11ms/step\n",
            "Epoch 125/200\n",
            "1/1 - 0s - loss: 0.4585 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 126/200\n",
            "1/1 - 0s - loss: 0.4491 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 127/200\n",
            "1/1 - 0s - loss: 0.4399 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 128/200\n",
            "1/1 - 0s - loss: 0.4309 - accuracy: 0.9091 - 13ms/epoch - 13ms/step\n",
            "Epoch 129/200\n",
            "1/1 - 0s - loss: 0.4220 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 130/200\n",
            "1/1 - 0s - loss: 0.4134 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 131/200\n",
            "1/1 - 0s - loss: 0.4048 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 132/200\n",
            "1/1 - 0s - loss: 0.3965 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 133/200\n",
            "1/1 - 0s - loss: 0.3882 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 134/200\n",
            "1/1 - 0s - loss: 0.3802 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
            "Epoch 135/200\n",
            "1/1 - 0s - loss: 0.3723 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 136/200\n",
            "1/1 - 0s - loss: 0.3646 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 137/200\n",
            "1/1 - 0s - loss: 0.3570 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 138/200\n",
            "1/1 - 0s - loss: 0.3496 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
            "Epoch 139/200\n",
            "1/1 - 0s - loss: 0.3423 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 140/200\n",
            "1/1 - 0s - loss: 0.3352 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 141/200\n",
            "1/1 - 0s - loss: 0.3282 - accuracy: 0.9091 - 11ms/epoch - 11ms/step\n",
            "Epoch 142/200\n",
            "1/1 - 0s - loss: 0.3214 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 143/200\n",
            "1/1 - 0s - loss: 0.3147 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 144/200\n",
            "1/1 - 0s - loss: 0.3082 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 145/200\n",
            "1/1 - 0s - loss: 0.3018 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 146/200\n",
            "1/1 - 0s - loss: 0.2955 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 147/200\n",
            "1/1 - 0s - loss: 0.2894 - accuracy: 0.9091 - 12ms/epoch - 12ms/step\n",
            "Epoch 148/200\n",
            "1/1 - 0s - loss: 0.2835 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
            "Epoch 149/200\n",
            "1/1 - 0s - loss: 0.2777 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 150/200\n",
            "1/1 - 0s - loss: 0.2720 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 151/200\n",
            "1/1 - 0s - loss: 0.2664 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
            "Epoch 152/200\n",
            "1/1 - 0s - loss: 0.2610 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 153/200\n",
            "1/1 - 0s - loss: 0.2557 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 154/200\n",
            "1/1 - 0s - loss: 0.2505 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 155/200\n",
            "1/1 - 0s - loss: 0.2454 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 156/200\n",
            "1/1 - 0s - loss: 0.2405 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 157/200\n",
            "1/1 - 0s - loss: 0.2357 - accuracy: 0.9091 - 9ms/epoch - 9ms/step\n",
            "Epoch 158/200\n",
            "1/1 - 0s - loss: 0.2310 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 159/200\n",
            "1/1 - 0s - loss: 0.2264 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 160/200\n",
            "1/1 - 0s - loss: 0.2219 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 161/200\n",
            "1/1 - 0s - loss: 0.2175 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 162/200\n",
            "1/1 - 0s - loss: 0.2132 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 163/200\n",
            "1/1 - 0s - loss: 0.2090 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 164/200\n",
            "1/1 - 0s - loss: 0.2049 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 165/200\n",
            "1/1 - 0s - loss: 0.2010 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 166/200\n",
            "1/1 - 0s - loss: 0.1971 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 167/200\n",
            "1/1 - 0s - loss: 0.1933 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 168/200\n",
            "1/1 - 0s - loss: 0.1895 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 169/200\n",
            "1/1 - 0s - loss: 0.1859 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 170/200\n",
            "1/1 - 0s - loss: 0.1824 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 171/200\n",
            "1/1 - 0s - loss: 0.1789 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 172/200\n",
            "1/1 - 0s - loss: 0.1755 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 173/200\n",
            "1/1 - 0s - loss: 0.1722 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 174/200\n",
            "1/1 - 0s - loss: 0.1690 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 175/200\n",
            "1/1 - 0s - loss: 0.1658 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 176/200\n",
            "1/1 - 0s - loss: 0.1627 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 177/200\n",
            "1/1 - 0s - loss: 0.1597 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 178/200\n",
            "1/1 - 0s - loss: 0.1568 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 179/200\n",
            "1/1 - 0s - loss: 0.1539 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 180/200\n",
            "1/1 - 0s - loss: 0.1510 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 181/200\n",
            "1/1 - 0s - loss: 0.1483 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 182/200\n",
            "1/1 - 0s - loss: 0.1456 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 183/200\n",
            "1/1 - 0s - loss: 0.1430 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 184/200\n",
            "1/1 - 0s - loss: 0.1404 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 185/200\n",
            "1/1 - 0s - loss: 0.1378 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 186/200\n",
            "1/1 - 0s - loss: 0.1354 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 187/200\n",
            "1/1 - 0s - loss: 0.1330 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 188/200\n",
            "1/1 - 0s - loss: 0.1306 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 189/200\n",
            "1/1 - 0s - loss: 0.1283 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 190/200\n",
            "1/1 - 0s - loss: 0.1260 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 191/200\n",
            "1/1 - 0s - loss: 0.1238 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 192/200\n",
            "1/1 - 0s - loss: 0.1217 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 193/200\n",
            "1/1 - 0s - loss: 0.1195 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 194/200\n",
            "1/1 - 0s - loss: 0.1175 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 195/200\n",
            "1/1 - 0s - loss: 0.1154 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 196/200\n",
            "1/1 - 0s - loss: 0.1135 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 197/200\n",
            "1/1 - 0s - loss: 0.1115 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 198/200\n",
            "1/1 - 0s - loss: 0.1096 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 199/200\n",
            "1/1 - 0s - loss: 0.1078 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 200/200\n",
            "1/1 - 0s - loss: 0.1059 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f17f708d090>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그 후 모델이 정확하게 예측하고 있는지 문장을 생성하는 함수를 만듦"
      ],
      "metadata": {
        "id": "zwJkVM1EWbFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "    init_word = current_word\n",
        "    sentence = ''\n",
        "\n",
        "    # n번 반복\n",
        "    for _ in range(n):\n",
        "        # 현재 단어에 대한 정수 인코딩과 패딩\n",
        "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
        "        # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
        "        result = model.predict(encoded, verbose=0)\n",
        "        result = np.argmax(result, axis=1)\n",
        "\n",
        "        for word, index in tokenizer.word_index.items(): \n",
        "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면 break\n",
        "            if index == result:\n",
        "                break\n",
        "\n",
        "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "        current_word = current_word + ' '  + word\n",
        "\n",
        "        # 예측 단어를 문장에 저장\n",
        "        sentence = sentence + ' ' + word\n",
        "\n",
        "    sentence = init_word + sentence\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "_agol9DKUdYQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'경마장에'라는 단어를 입력하고 이 모델은 충분한 훈련 데이터를 갖고 있지 못하므로<br>\n",
        "문장의 길이에 맞게 적절하게 예측해야 하는 횟수인 4번를 넣어 예측하면<br>\n",
        "앞의 문맥을 기준으로 '말이'라는 단어 다음에 나올 단어를 기존의 훈련 데이터와 일치하게 예측함을 보여줌"
      ],
      "metadata": {
        "id": "ubm_9C-AWd6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '경마장에', 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLFEQrboUd6g",
        "outputId": "c1d386bf-0ccf-44b5-ff96-dfa4a0483a69"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "경마장에 있는 말이 뛰고 있다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '그의', 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_MHGHGvUfCZ",
        "outputId": "a4a14bdf-6952-483c-f1dc-021cc3706b72"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "그의 말이 법이다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '가는', 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oChWCn8Uh08",
        "outputId": "1c9bdba2-525f-4b9f-dc0d-51ed0d461a2c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가는 말이 고와야 오는 말이 곱다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM을 이용하여 텍스트 생성하기"
      ],
      "metadata": {
        "id": "tj2uMxkbUDPT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) 데이터에 대한 이해와 전처리**"
      ],
      "metadata": {
        "id": "B2Tl1_fuUEgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "bA7i1oGCUga7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "뉴욕 타임즈 기사의 제목 데이터에 대해 가져온 후 다운로드한 훈련 데이터를 데이터프레임에 저장함"
      ],
      "metadata": {
        "id": "osOAlfNUWnXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skaqSWuCVQJE",
        "outputId": "590ad0dd-849c-4d55-f8ba-6c9a13a684b7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/Colab Notebooks/dataset/'"
      ],
      "metadata": {
        "id": "kMmkMMlpVQ2r"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(PATH + 'ArticlesApril2018.csv', encoding = 'utf-8-sig', low_memory=False)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "KF3JeV01UjSD",
        "outputId": "474368e9-c8b9-471d-abbd-7195b1d3ffb7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  articleID  articleWordCount  \\\n",
              "0  5adf6684068401528a2aa69b               781   \n",
              "1  5adf653f068401528a2aa697               656   \n",
              "2  5adf4626068401528a2aa628              2427   \n",
              "3  5adf40d2068401528a2aa619               626   \n",
              "4  5adf3d64068401528a2aa60f               815   \n",
              "\n",
              "                                      byline documentType  \\\n",
              "0                             By JOHN BRANCH      article   \n",
              "1                           By LISA FRIEDMAN      article   \n",
              "2                              By PETE WELLS      article   \n",
              "3  By JULIE HIRSCHFELD DAVIS and PETER BAKER      article   \n",
              "4             By IAN AUSTEN and DAN BILEFSKY      article   \n",
              "\n",
              "                                            headline  \\\n",
              "0  Former N.F.L. Cheerleaders’ Settlement Offer: ...   \n",
              "1  E.P.A. to Unveil a New Rule. Its Effect: Less ...   \n",
              "2                            The New Noma, Explained   \n",
              "3                                            Unknown   \n",
              "4                                            Unknown   \n",
              "\n",
              "                                            keywords  multimedia     newDesk  \\\n",
              "0  ['Workplace Hazards and Violations', 'Football...          68      Sports   \n",
              "1  ['Environmental Protection Agency', 'Pruitt, S...          68     Climate   \n",
              "2  ['Restaurants', 'Noma (Copenhagen, Restaurant)...          66      Dining   \n",
              "3  ['Macron, Emmanuel (1977- )', 'Trump, Donald J...          68  Washington   \n",
              "4  ['Toronto, Ontario, Attack (April, 2018)', 'Mu...          68     Foreign   \n",
              "\n",
              "   printPage              pubDate   sectionName  \\\n",
              "0          0  2018-04-24 17:16:49  Pro Football   \n",
              "1          0  2018-04-24 17:11:21       Unknown   \n",
              "2          0  2018-04-24 14:58:44       Unknown   \n",
              "3          0  2018-04-24 14:35:57        Europe   \n",
              "4          0  2018-04-24 14:21:21        Canada   \n",
              "\n",
              "                                             snippet              source  \\\n",
              "0  “I understand that they could meet with us, pa...  The New York Times   \n",
              "1  The agency plans to publish a new regulation T...  The New York Times   \n",
              "2  What’s it like to eat at the second incarnatio...  The New York Times   \n",
              "3  President Trump welcomed President Emmanuel Ma...  The New York Times   \n",
              "4  Alek Minassian, 25, a resident of Toronto’s Ri...  The New York Times   \n",
              "\n",
              "  typeOfMaterial                                             webURL  \n",
              "0           News  https://www.nytimes.com/2018/04/24/sports/foot...  \n",
              "1           News  https://www.nytimes.com/2018/04/24/climate/epa...  \n",
              "2           News  https://www.nytimes.com/2018/04/24/dining/noma...  \n",
              "3           News  https://www.nytimes.com/2018/04/24/world/europ...  \n",
              "4           News  https://www.nytimes.com/2018/04/24/world/canad...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5356bed9-e5ac-488a-8fe0-a3c62fe33242\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articleID</th>\n",
              "      <th>articleWordCount</th>\n",
              "      <th>byline</th>\n",
              "      <th>documentType</th>\n",
              "      <th>headline</th>\n",
              "      <th>keywords</th>\n",
              "      <th>multimedia</th>\n",
              "      <th>newDesk</th>\n",
              "      <th>printPage</th>\n",
              "      <th>pubDate</th>\n",
              "      <th>sectionName</th>\n",
              "      <th>snippet</th>\n",
              "      <th>source</th>\n",
              "      <th>typeOfMaterial</th>\n",
              "      <th>webURL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5adf6684068401528a2aa69b</td>\n",
              "      <td>781</td>\n",
              "      <td>By JOHN BRANCH</td>\n",
              "      <td>article</td>\n",
              "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
              "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
              "      <td>68</td>\n",
              "      <td>Sports</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:16:49</td>\n",
              "      <td>Pro Football</td>\n",
              "      <td>“I understand that they could meet with us, pa...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5adf653f068401528a2aa697</td>\n",
              "      <td>656</td>\n",
              "      <td>By LISA FRIEDMAN</td>\n",
              "      <td>article</td>\n",
              "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
              "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
              "      <td>68</td>\n",
              "      <td>Climate</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:11:21</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>The agency plans to publish a new regulation T...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5adf4626068401528a2aa628</td>\n",
              "      <td>2427</td>\n",
              "      <td>By PETE WELLS</td>\n",
              "      <td>article</td>\n",
              "      <td>The New Noma, Explained</td>\n",
              "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
              "      <td>66</td>\n",
              "      <td>Dining</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:58:44</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>What’s it like to eat at the second incarnatio...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5adf40d2068401528a2aa619</td>\n",
              "      <td>626</td>\n",
              "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
              "      <td>68</td>\n",
              "      <td>Washington</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:35:57</td>\n",
              "      <td>Europe</td>\n",
              "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5adf3d64068401528a2aa60f</td>\n",
              "      <td>815</td>\n",
              "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
              "      <td>68</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:21:21</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5356bed9-e5ac-488a-8fe0-a3c62fe33242')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5356bed9-e5ac-488a-8fe0-a3c62fe33242 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5356bed9-e5ac-488a-8fe0-a3c62fe33242');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "어떤 열이 있고, 열이 총 몇 개가 있는지 출력해보고 Null 값이 있는지도 확인"
      ],
      "metadata": {
        "id": "V6c66heDWqfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('열의 개수: ',len(df.columns))\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYKuFbfqUl7C",
        "outputId": "8b1dc91b-798b-474c-bf5e-e24dca4ab984"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "열의 개수:  15\n",
            "Index(['articleID', 'articleWordCount', 'byline', 'documentType', 'headline',\n",
            "       'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n",
            "       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['headline'].isnull().values.any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zowPNV4UmlN",
        "outputId": "61f89499-7c5b-46f9-f630-f847f15058b4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "headline 열에서 모든 신문 기사의 제목을 뽑아서 하나의 리스트로 저장한 후 상위 5개만 출력"
      ],
      "metadata": {
        "id": "8H_iQOW1WuCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "headline = []\n",
        "# 헤드라인의 값들을 리스트로 저장\n",
        "headline.extend(list(df.headline.values)) \n",
        "headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djQ75L2BUnay",
        "outputId": "e6b8ceab-6bea-4d6b-ad3e-7c6ba8786cf4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
              " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
              " 'The New Noma, Explained',\n",
              " 'Unknown',\n",
              " 'Unknown']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('총 샘플의 개수 : {}'.format(len(headline))) # 현재 샘플의 개수"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uuo1TJiUoCc",
        "outputId": "9166e445-c511-4abf-9ced-464d565bf027"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 개수 : 1324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 5개의 샘플에는 Unknown 값이 들어 있으므로 비록 Null 값은 아니지만 실습에 도움이 되지 않으므로 제거해주도록 함"
      ],
      "metadata": {
        "id": "ft7U5iiFWxuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unknown 값을 가진 샘플 제거\n",
        "headline = [word for word in headline if word != \"Unknown\"]\n",
        "print('노이즈값 제거 후 샘플의 개수 : {}'.format(len(headline)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dISC6tu9Upfy",
        "outputId": "e358f959-95c5-4a3f-c263-8dd166e3d598"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "노이즈값 제거 후 샘플의 개수 : 1214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리를 위해 구두점 제거와 단어의 소문자화를 진행한 후 샘플 5개를 출력"
      ],
      "metadata": {
        "id": "BAlHesOnW0fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def repreprocessing(raw_sentence):\n",
        "    preproceseed_sentence = raw_sentence.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    # 구두점 제거와 동시에 소문자화\n",
        "    return ''.join(word for word in preproceseed_sentence if word not in punctuation).lower()\n",
        "\n",
        "preporcessed_headline = [repreprocessing(x) for x in headline]\n",
        "preporcessed_headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN72usZxUqzy",
        "outputId": "a70f8f15-f63f-40a3-885b-a1bfd4efe654"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
              " 'epa to unveil a new rule its effect less science in policymaking',\n",
              " 'the new noma explained',\n",
              " 'how a bag of texas dirt  became a times tradition',\n",
              " 'is school a place for selfexpression']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "단어 집합을 만들고 정수 인코딩을 진행하면서 동시에 하나의 문장을 여러 줄로 분해하여 훈련 데이터를 구성하도록 함"
      ],
      "metadata": {
        "id": "xZNKgGiuW4HE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preporcessed_headline)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : %d' % vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJX3kjLUUr0d",
        "outputId": "aa29273a-d6bc-48ed-eccf-e8db2774d9ef"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 3494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = list()\n",
        "\n",
        "for sentence in preporcessed_headline:\n",
        "\n",
        "    # 각 샘플에 대한 정수 인코딩\n",
        "    encoded = tokenizer.texts_to_sequences([sentence])[0] \n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "sequences[:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EWG8t4EUstx",
        "outputId": "0599dd3d-8a96-4cca-8d21-42de4c6c74ca"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[99, 269],\n",
              " [99, 269, 371],\n",
              " [99, 269, 371, 1115],\n",
              " [99, 269, 371, 1115, 582],\n",
              " [99, 269, 371, 1115, 582, 52],\n",
              " [99, 269, 371, 1115, 582, 52, 7],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
              " [100, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "만들어진 단어 집합에 대해 어떤 정수가 어떤 단어를 의미하는지 알아보기 위해 인덱스로부터 단어를 찾는 함수를 생성"
      ],
      "metadata": {
        "id": "8ICa7s5sW6qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {}\n",
        "for key, value in tokenizer.word_index.items(): # 인덱스를 단어로 바꾸기 위해 index_to_word를 생성\n",
        "    index_to_word[value] = key\n",
        "\n",
        "print('빈도수 상위 582번 단어 : {}'.format(index_to_word[582]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qefsfzqUuRR",
        "outputId": "b0ecfe2c-69eb-43f1-a26e-64eb369b766c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "빈도수 상위 582번 단어 : offer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "레이블로 사용될 단어를 분리하지 않았으므로 전체 훈련 데이터에서 가장 긴 샘플의 길이를 이용해 전체 샘플의 길이를 패딩<br>\n",
        "그 후  전체 훈련 데이터에 대해서 맨 우측에 있는 단어에 대해서만 레이블로 분리하도록 함"
      ],
      "metadata": {
        "id": "C4Paad3pW9ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in sequences)\n",
        "print('샘플의 최대 길이 : {}'.format(max_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujzMELGuUu_Z",
        "outputId": "a3ea0785-face-4e06-c27d-05a1c1e1f713"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "print(sequences[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhUi6owsUvmo",
        "outputId": "4ac5a532-31f5-4843-b58e-8beb3b98b513"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0   99  269]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0   99  269  371]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0   99  269  371 1115]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1]"
      ],
      "metadata": {
        "id": "9tySDMKQUvrN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUh5hY2EUw76",
        "outputId": "6eec5f40-5eac-41b4-e4e1-e82e4a54bcc4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0  99]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0  99 269]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  99 269 371]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j48Kk-EiUxxY",
        "outputId": "fc8a49fc-2e7c-4f22-86fb-f8713046d9c4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 269  371 1115]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN 모델에 훈련 데이터를 훈련 시키기 전에 레이블에 대해서 원-핫 인코딩을 수행"
      ],
      "metadata": {
        "id": "v64EGzrBXCf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "BM7ZSSY7UyYa"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) 모델 설계하기**"
      ],
      "metadata": {
        "id": "ukSgHqhBUGN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM"
      ],
      "metadata": {
        "id": "62OmLPSMUzNj"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼파라미터인 임베딩 벡터의 차원은 10, 은닉 상태의 크기는 128로 하고 다 대 일 구조의 LSTM을 사용<br>\n",
        "전결합층을 출력층으로 하여 단어 집합 크기만큼의 뉴런을 배치하여 모델을 설계하도록 함<br>\n",
        "해당 모델은 마지막 시점에서 모든 가능한 단어 중 하나의 단어를 예측하는 다중 클래스 분류 문제를 수행하는 것이므로<br>\n",
        "출력층에서 활성화 함수로는 소프트맥스 함수를 사용하고, 손실 함수로는 크로스 엔트로피 함수를 사용하여 200 에포크 수행"
      ],
      "metadata": {
        "id": "C0fPyzhIXDtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 10\n",
        "hidden_units = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(LSTM(hidden_units))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzyvQeQQU0CR",
        "outputId": "0e2253ef-b09d-4ac6-9742-77a0c2603554"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "244/244 - 11s - loss: 7.6375 - accuracy: 0.0301 - 11s/epoch - 45ms/step\n",
            "Epoch 2/200\n",
            "244/244 - 9s - loss: 7.1167 - accuracy: 0.0286 - 9s/epoch - 36ms/step\n",
            "Epoch 3/200\n",
            "244/244 - 8s - loss: 6.9805 - accuracy: 0.0347 - 8s/epoch - 34ms/step\n",
            "Epoch 4/200\n",
            "244/244 - 9s - loss: 6.8537 - accuracy: 0.0388 - 9s/epoch - 35ms/step\n",
            "Epoch 5/200\n",
            "244/244 - 9s - loss: 6.7103 - accuracy: 0.0420 - 9s/epoch - 36ms/step\n",
            "Epoch 6/200\n",
            "244/244 - 9s - loss: 6.5557 - accuracy: 0.0451 - 9s/epoch - 37ms/step\n",
            "Epoch 7/200\n",
            "244/244 - 9s - loss: 6.3868 - accuracy: 0.0510 - 9s/epoch - 37ms/step\n",
            "Epoch 8/200\n",
            "244/244 - 9s - loss: 6.1986 - accuracy: 0.0552 - 9s/epoch - 36ms/step\n",
            "Epoch 9/200\n",
            "244/244 - 9s - loss: 6.0129 - accuracy: 0.0592 - 9s/epoch - 36ms/step\n",
            "Epoch 10/200\n",
            "244/244 - 9s - loss: 5.8369 - accuracy: 0.0638 - 9s/epoch - 35ms/step\n",
            "Epoch 11/200\n",
            "244/244 - 9s - loss: 5.6665 - accuracy: 0.0705 - 9s/epoch - 35ms/step\n",
            "Epoch 12/200\n",
            "244/244 - 8s - loss: 5.5056 - accuracy: 0.0757 - 8s/epoch - 35ms/step\n",
            "Epoch 13/200\n",
            "244/244 - 9s - loss: 5.3489 - accuracy: 0.0771 - 9s/epoch - 35ms/step\n",
            "Epoch 14/200\n",
            "244/244 - 9s - loss: 5.2004 - accuracy: 0.0836 - 9s/epoch - 36ms/step\n",
            "Epoch 15/200\n",
            "244/244 - 9s - loss: 5.0553 - accuracy: 0.0884 - 9s/epoch - 36ms/step\n",
            "Epoch 16/200\n",
            "244/244 - 9s - loss: 4.9130 - accuracy: 0.0986 - 9s/epoch - 36ms/step\n",
            "Epoch 17/200\n",
            "244/244 - 9s - loss: 4.7775 - accuracy: 0.1093 - 9s/epoch - 36ms/step\n",
            "Epoch 18/200\n",
            "244/244 - 9s - loss: 4.6501 - accuracy: 0.1187 - 9s/epoch - 36ms/step\n",
            "Epoch 19/200\n",
            "244/244 - 9s - loss: 4.5234 - accuracy: 0.1367 - 9s/epoch - 37ms/step\n",
            "Epoch 20/200\n",
            "244/244 - 9s - loss: 4.4001 - accuracy: 0.1526 - 9s/epoch - 37ms/step\n",
            "Epoch 21/200\n",
            "244/244 - 9s - loss: 4.2822 - accuracy: 0.1701 - 9s/epoch - 35ms/step\n",
            "Epoch 22/200\n",
            "244/244 - 10s - loss: 4.1677 - accuracy: 0.1912 - 10s/epoch - 43ms/step\n",
            "Epoch 23/200\n",
            "244/244 - 9s - loss: 4.0541 - accuracy: 0.2095 - 9s/epoch - 36ms/step\n",
            "Epoch 24/200\n",
            "244/244 - 9s - loss: 3.9449 - accuracy: 0.2258 - 9s/epoch - 36ms/step\n",
            "Epoch 25/200\n",
            "244/244 - 9s - loss: 3.8411 - accuracy: 0.2377 - 9s/epoch - 36ms/step\n",
            "Epoch 26/200\n",
            "244/244 - 9s - loss: 3.7415 - accuracy: 0.2577 - 9s/epoch - 37ms/step\n",
            "Epoch 27/200\n",
            "244/244 - 9s - loss: 3.6401 - accuracy: 0.2717 - 9s/epoch - 38ms/step\n",
            "Epoch 28/200\n",
            "244/244 - 9s - loss: 3.5452 - accuracy: 0.2918 - 9s/epoch - 37ms/step\n",
            "Epoch 29/200\n",
            "244/244 - 9s - loss: 3.4544 - accuracy: 0.3050 - 9s/epoch - 35ms/step\n",
            "Epoch 30/200\n",
            "244/244 - 8s - loss: 3.3652 - accuracy: 0.3226 - 8s/epoch - 34ms/step\n",
            "Epoch 31/200\n",
            "244/244 - 9s - loss: 3.2783 - accuracy: 0.3364 - 9s/epoch - 36ms/step\n",
            "Epoch 32/200\n",
            "244/244 - 9s - loss: 3.1963 - accuracy: 0.3524 - 9s/epoch - 35ms/step\n",
            "Epoch 33/200\n",
            "244/244 - 8s - loss: 3.1177 - accuracy: 0.3664 - 8s/epoch - 35ms/step\n",
            "Epoch 34/200\n",
            "244/244 - 9s - loss: 3.0394 - accuracy: 0.3769 - 9s/epoch - 36ms/step\n",
            "Epoch 35/200\n",
            "244/244 - 9s - loss: 2.9668 - accuracy: 0.3923 - 9s/epoch - 35ms/step\n",
            "Epoch 36/200\n",
            "244/244 - 9s - loss: 2.8948 - accuracy: 0.4089 - 9s/epoch - 35ms/step\n",
            "Epoch 37/200\n",
            "244/244 - 9s - loss: 2.8257 - accuracy: 0.4200 - 9s/epoch - 36ms/step\n",
            "Epoch 38/200\n",
            "244/244 - 9s - loss: 2.7604 - accuracy: 0.4352 - 9s/epoch - 35ms/step\n",
            "Epoch 39/200\n",
            "244/244 - 9s - loss: 2.6950 - accuracy: 0.4461 - 9s/epoch - 36ms/step\n",
            "Epoch 40/200\n",
            "244/244 - 9s - loss: 2.6320 - accuracy: 0.4544 - 9s/epoch - 37ms/step\n",
            "Epoch 41/200\n",
            "244/244 - 9s - loss: 2.5706 - accuracy: 0.4669 - 9s/epoch - 35ms/step\n",
            "Epoch 42/200\n",
            "244/244 - 9s - loss: 2.5105 - accuracy: 0.4862 - 9s/epoch - 36ms/step\n",
            "Epoch 43/200\n",
            "244/244 - 8s - loss: 2.4523 - accuracy: 0.4938 - 8s/epoch - 35ms/step\n",
            "Epoch 44/200\n",
            "244/244 - 9s - loss: 2.3970 - accuracy: 0.5042 - 9s/epoch - 36ms/step\n",
            "Epoch 45/200\n",
            "244/244 - 10s - loss: 2.3410 - accuracy: 0.5169 - 10s/epoch - 42ms/step\n",
            "Epoch 46/200\n",
            "244/244 - 9s - loss: 2.2909 - accuracy: 0.5315 - 9s/epoch - 35ms/step\n",
            "Epoch 47/200\n",
            "244/244 - 8s - loss: 2.2356 - accuracy: 0.5398 - 8s/epoch - 34ms/step\n",
            "Epoch 48/200\n",
            "244/244 - 9s - loss: 2.1877 - accuracy: 0.5497 - 9s/epoch - 35ms/step\n",
            "Epoch 49/200\n",
            "244/244 - 8s - loss: 2.1365 - accuracy: 0.5597 - 8s/epoch - 34ms/step\n",
            "Epoch 50/200\n",
            "244/244 - 9s - loss: 2.0883 - accuracy: 0.5714 - 9s/epoch - 36ms/step\n",
            "Epoch 51/200\n",
            "244/244 - 8s - loss: 2.0404 - accuracy: 0.5837 - 8s/epoch - 33ms/step\n",
            "Epoch 52/200\n",
            "244/244 - 9s - loss: 1.9975 - accuracy: 0.5896 - 9s/epoch - 36ms/step\n",
            "Epoch 53/200\n",
            "244/244 - 9s - loss: 1.9533 - accuracy: 0.6002 - 9s/epoch - 36ms/step\n",
            "Epoch 54/200\n",
            "244/244 - 9s - loss: 1.9069 - accuracy: 0.6078 - 9s/epoch - 36ms/step\n",
            "Epoch 55/200\n",
            "244/244 - 9s - loss: 1.8615 - accuracy: 0.6186 - 9s/epoch - 35ms/step\n",
            "Epoch 56/200\n",
            "244/244 - 9s - loss: 1.8206 - accuracy: 0.6277 - 9s/epoch - 35ms/step\n",
            "Epoch 57/200\n",
            "244/244 - 9s - loss: 1.7777 - accuracy: 0.6372 - 9s/epoch - 35ms/step\n",
            "Epoch 58/200\n",
            "244/244 - 9s - loss: 1.7377 - accuracy: 0.6458 - 9s/epoch - 36ms/step\n",
            "Epoch 59/200\n",
            "244/244 - 9s - loss: 1.6991 - accuracy: 0.6554 - 9s/epoch - 36ms/step\n",
            "Epoch 60/200\n",
            "244/244 - 9s - loss: 1.6585 - accuracy: 0.6645 - 9s/epoch - 36ms/step\n",
            "Epoch 61/200\n",
            "244/244 - 9s - loss: 1.6216 - accuracy: 0.6714 - 9s/epoch - 35ms/step\n",
            "Epoch 62/200\n",
            "244/244 - 8s - loss: 1.5832 - accuracy: 0.6776 - 8s/epoch - 35ms/step\n",
            "Epoch 63/200\n",
            "244/244 - 9s - loss: 1.5468 - accuracy: 0.6859 - 9s/epoch - 36ms/step\n",
            "Epoch 64/200\n",
            "244/244 - 9s - loss: 1.5134 - accuracy: 0.6906 - 9s/epoch - 36ms/step\n",
            "Epoch 65/200\n",
            "244/244 - 9s - loss: 1.4767 - accuracy: 0.7023 - 9s/epoch - 37ms/step\n",
            "Epoch 66/200\n",
            "244/244 - 9s - loss: 1.4431 - accuracy: 0.7109 - 9s/epoch - 35ms/step\n",
            "Epoch 67/200\n",
            "244/244 - 8s - loss: 1.4088 - accuracy: 0.7163 - 8s/epoch - 34ms/step\n",
            "Epoch 68/200\n",
            "244/244 - 9s - loss: 1.3752 - accuracy: 0.7247 - 9s/epoch - 36ms/step\n",
            "Epoch 69/200\n",
            "244/244 - 10s - loss: 1.3432 - accuracy: 0.7319 - 10s/epoch - 42ms/step\n",
            "Epoch 70/200\n",
            "244/244 - 9s - loss: 1.3123 - accuracy: 0.7348 - 9s/epoch - 35ms/step\n",
            "Epoch 71/200\n",
            "244/244 - 9s - loss: 1.2820 - accuracy: 0.7457 - 9s/epoch - 36ms/step\n",
            "Epoch 72/200\n",
            "244/244 - 9s - loss: 1.2517 - accuracy: 0.7504 - 9s/epoch - 36ms/step\n",
            "Epoch 73/200\n",
            "244/244 - 9s - loss: 1.2214 - accuracy: 0.7562 - 9s/epoch - 36ms/step\n",
            "Epoch 74/200\n",
            "244/244 - 9s - loss: 1.1969 - accuracy: 0.7592 - 9s/epoch - 35ms/step\n",
            "Epoch 75/200\n",
            "244/244 - 9s - loss: 1.1674 - accuracy: 0.7686 - 9s/epoch - 37ms/step\n",
            "Epoch 76/200\n",
            "244/244 - 9s - loss: 1.1375 - accuracy: 0.7762 - 9s/epoch - 37ms/step\n",
            "Epoch 77/200\n",
            "244/244 - 9s - loss: 1.1118 - accuracy: 0.7779 - 9s/epoch - 35ms/step\n",
            "Epoch 78/200\n",
            "244/244 - 9s - loss: 1.0875 - accuracy: 0.7826 - 9s/epoch - 36ms/step\n",
            "Epoch 79/200\n",
            "244/244 - 9s - loss: 1.0609 - accuracy: 0.7910 - 9s/epoch - 37ms/step\n",
            "Epoch 80/200\n",
            "244/244 - 9s - loss: 1.0343 - accuracy: 0.7934 - 9s/epoch - 35ms/step\n",
            "Epoch 81/200\n",
            "244/244 - 9s - loss: 1.0116 - accuracy: 0.8007 - 9s/epoch - 37ms/step\n",
            "Epoch 82/200\n",
            "244/244 - 9s - loss: 0.9856 - accuracy: 0.8048 - 9s/epoch - 35ms/step\n",
            "Epoch 83/200\n",
            "244/244 - 9s - loss: 0.9640 - accuracy: 0.8085 - 9s/epoch - 37ms/step\n",
            "Epoch 84/200\n",
            "244/244 - 9s - loss: 0.9412 - accuracy: 0.8143 - 9s/epoch - 38ms/step\n",
            "Epoch 85/200\n",
            "244/244 - 9s - loss: 0.9201 - accuracy: 0.8189 - 9s/epoch - 38ms/step\n",
            "Epoch 86/200\n",
            "244/244 - 9s - loss: 0.9027 - accuracy: 0.8248 - 9s/epoch - 36ms/step\n",
            "Epoch 87/200\n",
            "244/244 - 9s - loss: 0.8801 - accuracy: 0.8262 - 9s/epoch - 36ms/step\n",
            "Epoch 88/200\n",
            "244/244 - 9s - loss: 0.8590 - accuracy: 0.8288 - 9s/epoch - 36ms/step\n",
            "Epoch 89/200\n",
            "244/244 - 9s - loss: 0.8369 - accuracy: 0.8340 - 9s/epoch - 36ms/step\n",
            "Epoch 90/200\n",
            "244/244 - 9s - loss: 0.8189 - accuracy: 0.8378 - 9s/epoch - 35ms/step\n",
            "Epoch 91/200\n",
            "244/244 - 9s - loss: 0.8002 - accuracy: 0.8413 - 9s/epoch - 35ms/step\n",
            "Epoch 92/200\n",
            "244/244 - 10s - loss: 0.7807 - accuracy: 0.8454 - 10s/epoch - 42ms/step\n",
            "Epoch 93/200\n",
            "244/244 - 9s - loss: 0.7716 - accuracy: 0.8492 - 9s/epoch - 36ms/step\n",
            "Epoch 94/200\n",
            "244/244 - 9s - loss: 0.7486 - accuracy: 0.8522 - 9s/epoch - 37ms/step\n",
            "Epoch 95/200\n",
            "244/244 - 9s - loss: 0.7322 - accuracy: 0.8544 - 9s/epoch - 37ms/step\n",
            "Epoch 96/200\n",
            "244/244 - 9s - loss: 0.7127 - accuracy: 0.8597 - 9s/epoch - 36ms/step\n",
            "Epoch 97/200\n",
            "244/244 - 8s - loss: 0.6979 - accuracy: 0.8621 - 8s/epoch - 35ms/step\n",
            "Epoch 98/200\n",
            "244/244 - 9s - loss: 0.6824 - accuracy: 0.8657 - 9s/epoch - 36ms/step\n",
            "Epoch 99/200\n",
            "244/244 - 9s - loss: 0.6675 - accuracy: 0.8672 - 9s/epoch - 36ms/step\n",
            "Epoch 100/200\n",
            "244/244 - 8s - loss: 0.6535 - accuracy: 0.8720 - 8s/epoch - 34ms/step\n",
            "Epoch 101/200\n",
            "244/244 - 8s - loss: 0.6384 - accuracy: 0.8743 - 8s/epoch - 34ms/step\n",
            "Epoch 102/200\n",
            "244/244 - 9s - loss: 0.6267 - accuracy: 0.8779 - 9s/epoch - 36ms/step\n",
            "Epoch 103/200\n",
            "244/244 - 8s - loss: 0.6245 - accuracy: 0.8780 - 8s/epoch - 34ms/step\n",
            "Epoch 104/200\n",
            "244/244 - 9s - loss: 0.6003 - accuracy: 0.8815 - 9s/epoch - 35ms/step\n",
            "Epoch 105/200\n",
            "244/244 - 8s - loss: 0.5862 - accuracy: 0.8839 - 8s/epoch - 33ms/step\n",
            "Epoch 106/200\n",
            "244/244 - 9s - loss: 0.5730 - accuracy: 0.8857 - 9s/epoch - 35ms/step\n",
            "Epoch 107/200\n",
            "244/244 - 9s - loss: 0.5642 - accuracy: 0.8872 - 9s/epoch - 35ms/step\n",
            "Epoch 108/200\n",
            "244/244 - 9s - loss: 0.5509 - accuracy: 0.8890 - 9s/epoch - 36ms/step\n",
            "Epoch 109/200\n",
            "244/244 - 9s - loss: 0.5401 - accuracy: 0.8916 - 9s/epoch - 35ms/step\n",
            "Epoch 110/200\n",
            "244/244 - 8s - loss: 0.5290 - accuracy: 0.8954 - 8s/epoch - 34ms/step\n",
            "Epoch 111/200\n",
            "244/244 - 8s - loss: 0.5169 - accuracy: 0.8979 - 8s/epoch - 35ms/step\n",
            "Epoch 112/200\n",
            "244/244 - 9s - loss: 0.5073 - accuracy: 0.8967 - 9s/epoch - 36ms/step\n",
            "Epoch 113/200\n",
            "244/244 - 9s - loss: 0.4994 - accuracy: 0.8986 - 9s/epoch - 36ms/step\n",
            "Epoch 114/200\n",
            "244/244 - 8s - loss: 0.4886 - accuracy: 0.8984 - 8s/epoch - 35ms/step\n",
            "Epoch 115/200\n",
            "244/244 - 10s - loss: 0.4805 - accuracy: 0.9004 - 10s/epoch - 39ms/step\n",
            "Epoch 116/200\n",
            "244/244 - 9s - loss: 0.4695 - accuracy: 0.9029 - 9s/epoch - 38ms/step\n",
            "Epoch 117/200\n",
            "244/244 - 9s - loss: 0.4640 - accuracy: 0.9032 - 9s/epoch - 35ms/step\n",
            "Epoch 118/200\n",
            "244/244 - 9s - loss: 0.4540 - accuracy: 0.9066 - 9s/epoch - 36ms/step\n",
            "Epoch 119/200\n",
            "244/244 - 9s - loss: 0.4512 - accuracy: 0.9048 - 9s/epoch - 35ms/step\n",
            "Epoch 120/200\n",
            "244/244 - 8s - loss: 0.4546 - accuracy: 0.9049 - 8s/epoch - 35ms/step\n",
            "Epoch 121/200\n",
            "244/244 - 9s - loss: 0.4322 - accuracy: 0.9090 - 9s/epoch - 35ms/step\n",
            "Epoch 122/200\n",
            "244/244 - 9s - loss: 0.4202 - accuracy: 0.9099 - 9s/epoch - 37ms/step\n",
            "Epoch 123/200\n",
            "244/244 - 8s - loss: 0.4121 - accuracy: 0.9081 - 8s/epoch - 35ms/step\n",
            "Epoch 124/200\n",
            "244/244 - 8s - loss: 0.4075 - accuracy: 0.9099 - 8s/epoch - 34ms/step\n",
            "Epoch 125/200\n",
            "244/244 - 9s - loss: 0.4082 - accuracy: 0.9100 - 9s/epoch - 36ms/step\n",
            "Epoch 126/200\n",
            "244/244 - 9s - loss: 0.3951 - accuracy: 0.9130 - 9s/epoch - 36ms/step\n",
            "Epoch 127/200\n",
            "244/244 - 9s - loss: 0.3889 - accuracy: 0.9118 - 9s/epoch - 36ms/step\n",
            "Epoch 128/200\n",
            "244/244 - 8s - loss: 0.3824 - accuracy: 0.9134 - 8s/epoch - 34ms/step\n",
            "Epoch 129/200\n",
            "244/244 - 8s - loss: 0.3789 - accuracy: 0.9125 - 8s/epoch - 33ms/step\n",
            "Epoch 130/200\n",
            "244/244 - 8s - loss: 0.3755 - accuracy: 0.9120 - 8s/epoch - 35ms/step\n",
            "Epoch 131/200\n",
            "244/244 - 9s - loss: 0.3671 - accuracy: 0.9139 - 9s/epoch - 37ms/step\n",
            "Epoch 132/200\n",
            "244/244 - 9s - loss: 0.3620 - accuracy: 0.9139 - 9s/epoch - 36ms/step\n",
            "Epoch 133/200\n",
            "244/244 - 9s - loss: 0.3559 - accuracy: 0.9145 - 9s/epoch - 35ms/step\n",
            "Epoch 134/200\n",
            "244/244 - 9s - loss: 0.3541 - accuracy: 0.9149 - 9s/epoch - 35ms/step\n",
            "Epoch 135/200\n",
            "244/244 - 8s - loss: 0.3489 - accuracy: 0.9149 - 8s/epoch - 34ms/step\n",
            "Epoch 136/200\n",
            "244/244 - 9s - loss: 0.3448 - accuracy: 0.9161 - 9s/epoch - 35ms/step\n",
            "Epoch 137/200\n",
            "244/244 - 9s - loss: 0.3407 - accuracy: 0.9126 - 9s/epoch - 36ms/step\n",
            "Epoch 138/200\n",
            "244/244 - 9s - loss: 0.3483 - accuracy: 0.9149 - 9s/epoch - 36ms/step\n",
            "Epoch 139/200\n",
            "244/244 - 10s - loss: 0.3478 - accuracy: 0.9141 - 10s/epoch - 41ms/step\n",
            "Epoch 140/200\n",
            "244/244 - 9s - loss: 0.3341 - accuracy: 0.9158 - 9s/epoch - 35ms/step\n",
            "Epoch 141/200\n",
            "244/244 - 9s - loss: 0.3264 - accuracy: 0.9164 - 9s/epoch - 37ms/step\n",
            "Epoch 142/200\n",
            "244/244 - 9s - loss: 0.3224 - accuracy: 0.9153 - 9s/epoch - 36ms/step\n",
            "Epoch 143/200\n",
            "244/244 - 8s - loss: 0.3184 - accuracy: 0.9159 - 8s/epoch - 35ms/step\n",
            "Epoch 144/200\n",
            "244/244 - 9s - loss: 0.3169 - accuracy: 0.9166 - 9s/epoch - 35ms/step\n",
            "Epoch 145/200\n",
            "244/244 - 9s - loss: 0.3125 - accuracy: 0.9167 - 9s/epoch - 35ms/step\n",
            "Epoch 146/200\n",
            "244/244 - 9s - loss: 0.3111 - accuracy: 0.9152 - 9s/epoch - 36ms/step\n",
            "Epoch 147/200\n",
            "244/244 - 9s - loss: 0.3101 - accuracy: 0.9159 - 9s/epoch - 35ms/step\n",
            "Epoch 148/200\n",
            "244/244 - 9s - loss: 0.3078 - accuracy: 0.9171 - 9s/epoch - 36ms/step\n",
            "Epoch 149/200\n",
            "244/244 - 9s - loss: 0.3051 - accuracy: 0.9163 - 9s/epoch - 36ms/step\n",
            "Epoch 150/200\n",
            "244/244 - 8s - loss: 0.3017 - accuracy: 0.9172 - 8s/epoch - 34ms/step\n",
            "Epoch 151/200\n",
            "244/244 - 8s - loss: 0.2991 - accuracy: 0.9163 - 8s/epoch - 34ms/step\n",
            "Epoch 152/200\n",
            "244/244 - 9s - loss: 0.2997 - accuracy: 0.9162 - 9s/epoch - 35ms/step\n",
            "Epoch 153/200\n",
            "244/244 - 9s - loss: 0.2993 - accuracy: 0.9163 - 9s/epoch - 36ms/step\n",
            "Epoch 154/200\n",
            "244/244 - 9s - loss: 0.2966 - accuracy: 0.9173 - 9s/epoch - 36ms/step\n",
            "Epoch 155/200\n",
            "244/244 - 9s - loss: 0.3076 - accuracy: 0.9145 - 9s/epoch - 37ms/step\n",
            "Epoch 156/200\n",
            "244/244 - 8s - loss: 0.3051 - accuracy: 0.9138 - 8s/epoch - 35ms/step\n",
            "Epoch 157/200\n",
            "244/244 - 8s - loss: 0.2944 - accuracy: 0.9172 - 8s/epoch - 34ms/step\n",
            "Epoch 158/200\n",
            "244/244 - 8s - loss: 0.2884 - accuracy: 0.9176 - 8s/epoch - 34ms/step\n",
            "Epoch 159/200\n",
            "244/244 - 9s - loss: 0.2866 - accuracy: 0.9159 - 9s/epoch - 35ms/step\n",
            "Epoch 160/200\n",
            "244/244 - 9s - loss: 0.2852 - accuracy: 0.9162 - 9s/epoch - 35ms/step\n",
            "Epoch 161/200\n",
            "244/244 - 9s - loss: 0.2839 - accuracy: 0.9179 - 9s/epoch - 36ms/step\n",
            "Epoch 162/200\n",
            "244/244 - 9s - loss: 0.2834 - accuracy: 0.9153 - 9s/epoch - 36ms/step\n",
            "Epoch 163/200\n",
            "244/244 - 10s - loss: 0.2824 - accuracy: 0.9176 - 10s/epoch - 41ms/step\n",
            "Epoch 164/200\n",
            "244/244 - 9s - loss: 0.2805 - accuracy: 0.9161 - 9s/epoch - 35ms/step\n",
            "Epoch 165/200\n",
            "244/244 - 9s - loss: 0.2819 - accuracy: 0.9167 - 9s/epoch - 36ms/step\n",
            "Epoch 166/200\n",
            "244/244 - 9s - loss: 0.2804 - accuracy: 0.9168 - 9s/epoch - 36ms/step\n",
            "Epoch 167/200\n",
            "244/244 - 9s - loss: 0.2776 - accuracy: 0.9172 - 9s/epoch - 36ms/step\n",
            "Epoch 168/200\n",
            "244/244 - 8s - loss: 0.2769 - accuracy: 0.9158 - 8s/epoch - 35ms/step\n",
            "Epoch 169/200\n",
            "244/244 - 9s - loss: 0.2786 - accuracy: 0.9163 - 9s/epoch - 36ms/step\n",
            "Epoch 170/200\n",
            "244/244 - 9s - loss: 0.2769 - accuracy: 0.9166 - 9s/epoch - 35ms/step\n",
            "Epoch 171/200\n",
            "244/244 - 9s - loss: 0.2765 - accuracy: 0.9173 - 9s/epoch - 35ms/step\n",
            "Epoch 172/200\n",
            "244/244 - 9s - loss: 0.2786 - accuracy: 0.9154 - 9s/epoch - 35ms/step\n",
            "Epoch 173/200\n",
            "244/244 - 9s - loss: 0.2865 - accuracy: 0.9150 - 9s/epoch - 35ms/step\n",
            "Epoch 174/200\n",
            "244/244 - 8s - loss: 0.2992 - accuracy: 0.9112 - 8s/epoch - 34ms/step\n",
            "Epoch 175/200\n",
            "244/244 - 9s - loss: 0.2867 - accuracy: 0.9164 - 9s/epoch - 36ms/step\n",
            "Epoch 176/200\n",
            "244/244 - 9s - loss: 0.2731 - accuracy: 0.9166 - 9s/epoch - 36ms/step\n",
            "Epoch 177/200\n",
            "244/244 - 9s - loss: 0.2692 - accuracy: 0.9168 - 9s/epoch - 37ms/step\n",
            "Epoch 178/200\n",
            "244/244 - 9s - loss: 0.2696 - accuracy: 0.9173 - 9s/epoch - 35ms/step\n",
            "Epoch 179/200\n",
            "244/244 - 9s - loss: 0.2685 - accuracy: 0.9170 - 9s/epoch - 37ms/step\n",
            "Epoch 180/200\n",
            "244/244 - 9s - loss: 0.2682 - accuracy: 0.9162 - 9s/epoch - 36ms/step\n",
            "Epoch 181/200\n",
            "244/244 - 9s - loss: 0.2682 - accuracy: 0.9158 - 9s/epoch - 35ms/step\n",
            "Epoch 182/200\n",
            "244/244 - 9s - loss: 0.2664 - accuracy: 0.9161 - 9s/epoch - 36ms/step\n",
            "Epoch 183/200\n",
            "244/244 - 9s - loss: 0.2671 - accuracy: 0.9171 - 9s/epoch - 35ms/step\n",
            "Epoch 184/200\n",
            "244/244 - 9s - loss: 0.2669 - accuracy: 0.9177 - 9s/epoch - 36ms/step\n",
            "Epoch 185/200\n",
            "244/244 - 9s - loss: 0.2659 - accuracy: 0.9173 - 9s/epoch - 36ms/step\n",
            "Epoch 186/200\n",
            "244/244 - 10s - loss: 0.2661 - accuracy: 0.9163 - 10s/epoch - 40ms/step\n",
            "Epoch 187/200\n",
            "244/244 - 8s - loss: 0.2653 - accuracy: 0.9173 - 8s/epoch - 35ms/step\n",
            "Epoch 188/200\n",
            "244/244 - 9s - loss: 0.2656 - accuracy: 0.9170 - 9s/epoch - 35ms/step\n",
            "Epoch 189/200\n",
            "244/244 - 8s - loss: 0.2654 - accuracy: 0.9187 - 8s/epoch - 34ms/step\n",
            "Epoch 190/200\n",
            "244/244 - 9s - loss: 0.2674 - accuracy: 0.9152 - 9s/epoch - 36ms/step\n",
            "Epoch 191/200\n",
            "244/244 - 9s - loss: 0.2641 - accuracy: 0.9173 - 9s/epoch - 37ms/step\n",
            "Epoch 192/200\n",
            "244/244 - 9s - loss: 0.2644 - accuracy: 0.9153 - 9s/epoch - 37ms/step\n",
            "Epoch 193/200\n",
            "244/244 - 9s - loss: 0.2631 - accuracy: 0.9162 - 9s/epoch - 36ms/step\n",
            "Epoch 194/200\n",
            "244/244 - 9s - loss: 0.2653 - accuracy: 0.9182 - 9s/epoch - 36ms/step\n",
            "Epoch 195/200\n",
            "244/244 - 9s - loss: 0.2663 - accuracy: 0.9159 - 9s/epoch - 36ms/step\n",
            "Epoch 196/200\n",
            "244/244 - 9s - loss: 0.2639 - accuracy: 0.9171 - 9s/epoch - 36ms/step\n",
            "Epoch 197/200\n",
            "244/244 - 9s - loss: 0.2628 - accuracy: 0.9180 - 9s/epoch - 36ms/step\n",
            "Epoch 198/200\n",
            "244/244 - 9s - loss: 0.2638 - accuracy: 0.9164 - 9s/epoch - 37ms/step\n",
            "Epoch 199/200\n",
            "244/244 - 9s - loss: 0.2646 - accuracy: 0.9159 - 9s/epoch - 37ms/step\n",
            "Epoch 200/200\n",
            "244/244 - 9s - loss: 0.2625 - accuracy: 0.9159 - 9s/epoch - 37ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f17f2a83890>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델이 정확하게 예측하고 있는지 문장을 생성하는 함수를 만듦"
      ],
      "metadata": {
        "id": "rClgvz1EXJdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "    init_word = current_word\n",
        "    sentence = ''\n",
        "\n",
        "    # n번 반복\n",
        "    for _ in range(n):\n",
        "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre')\n",
        "\n",
        "        # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
        "        result = model.predict(encoded, verbose=0)\n",
        "        result = np.argmax(result, axis=1)\n",
        "\n",
        "        for word, index in tokenizer.word_index.items(): \n",
        "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
        "            if index == result:\n",
        "                break\n",
        "\n",
        "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "        current_word = current_word + ' '  + word\n",
        "\n",
        "        # 예측 단어를 문장에 저장\n",
        "        sentence = sentence + ' ' + word\n",
        "\n",
        "    sentence = init_word + sentence\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "4nwGx_gAU1o8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "임의의 단어 'i'에 대해서 10개의 단어와 'how'에 대한 10개의 단어를 추가 생성해보도록 함"
      ],
      "metadata": {
        "id": "S0qBXviMXNXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, 'i', 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "henxvoHKU3IY",
        "outputId": "6c3f6566-1832-4f46-8534-75a14d4ca07b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i cant jump ship from facebook yet urge war at its\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, 'how', 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7J8_8NTU3-K",
        "outputId": "8bb05497-b9f5-4207-a00e-1efd3acdc9d1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how to serve a deranged tyrant stoically has the debates student\n"
          ]
        }
      ]
    }
  ]
}